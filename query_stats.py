#!/usr/bin/env python3
"""æ•°æ®åº“æŸ¥è¯¢ä¸ç»Ÿè®¡å·¥å…·

ç”¨é€”ï¼š
- æŸ¥çœ‹åˆ†æå¿«ç…§å†å²
- æŸ¥çœ‹ç»“æœå›å¡«è®°å½•
- ç»Ÿè®¡ AI é¢„æµ‹å‡†ç¡®ç‡
- å¯¼å‡º CSV æ–‡ä»¶

ä½¿ç”¨æ–¹æ³•ï¼š
    python query_stats.py                    # æ˜¾ç¤ºæ‰€æœ‰ç»Ÿè®¡
    python query_stats.py --snapshots        # åªæ˜¾ç¤ºå¿«ç…§åˆ—è¡¨
    python query_stats.py --outcomes         # åªæ˜¾ç¤ºç»“æœåˆ—è¡¨
    python query_stats.py --accuracy         # åªæ˜¾ç¤ºå‡†ç¡®ç‡ç»Ÿè®¡
    python query_stats.py --export-csv results.csv  # å¯¼å‡ºç»“æœåˆ° CSV
"""
import sqlite3
import argparse
import csv
import json
from pathlib import Path
from datetime import datetime

DB_PATH = Path(__file__).parent / "chanlun_ai.db"


def get_db_conn():
    """è·å–æ•°æ®åº“è¿æ¥"""
    return sqlite3.connect(DB_PATH)


def query_snapshots(limit: int = 10):
    """æŸ¥è¯¢æœ€è¿‘çš„åˆ†æå¿«ç…§"""
    conn = get_db_conn()
    c = conn.cursor()
    
    c.execute("""
        SELECT id, symbol, interval, timestamp, price, 
               CASE WHEN ai_json IS NOT NULL THEN 'æ˜¯' ELSE 'å¦' END as has_ai
        FROM analysis_snapshot
        ORDER BY timestamp DESC
        LIMIT ?
    """, (limit,))
    
    rows = c.fetchall()
    conn.close()
    
    return rows


def query_outcomes(limit: int = 10):
    """æŸ¥è¯¢æœ€è¿‘çš„ç»“æœå›å¡«è®°å½•ï¼ˆåŸºäº analysis_snapshot.outcome_jsonï¼‰"""
    conn = get_db_conn()
    c = conn.cursor()
    
    c.execute(
        """
        SELECT id, symbol, interval, timestamp, price, outcome_json
        FROM analysis_snapshot
        WHERE evaluated = 1 AND outcome_json IS NOT NULL
        ORDER BY timestamp DESC
        LIMIT ?
        """,
        (limit,),
    )
    
    rows = c.fetchall()
    conn.close()
    
    return rows

def calculate_accuracy():
    """è®¡ç®— AI é¢„æµ‹å‡†ç¡®ç‡ç»Ÿè®¡ï¼ˆåŸºäº analysis_snapshot.outcome_jsonï¼‰"""
    conn = get_db_conn()
    c = conn.cursor()
    
    c.execute(
        """
        SELECT outcome_json, symbol, interval
        FROM analysis_snapshot
        WHERE evaluated = 1 AND outcome_json IS NOT NULL
        """
    )
    rows = c.fetchall()
    conn.close()
    
    import json
    
    total = 0
    hit_count = 0
    by_direction_map = {}
    by_symbol_map = {}
    by_interval_map = {}
    by_outcome_map = {}
    total_score = 0
    
    for (outcome_json_str, symbol, interval) in rows:
        try:
            outcome = json.loads(outcome_json_str)
        except Exception:
            continue
        
        total += 1
        direction = outcome.get("direction", "unknown")
        hit_target = outcome.get("hit_target", False)
        outcome_type = outcome.get("outcome", "unknown")
        score = outcome.get("score", 0)
        
        total_score += score
        
        if hit_target:
            hit_count += 1
        
        # æŒ‰æ–¹å‘ç»Ÿè®¡
        stats = by_direction_map.setdefault(direction, {"total": 0, "hit": 0, "score": 0})
        stats["total"] += 1
        stats["score"] += score
        if hit_target:
            stats["hit"] += 1
        
        # æŒ‰äº¤æ˜“å¯¹ç»Ÿè®¡
        stats = by_symbol_map.setdefault(symbol, {"total": 0, "hit": 0, "score": 0})
        stats["total"] += 1
        stats["score"] += score
        if hit_target:
            stats["hit"] += 1
        
        # æŒ‰å‘¨æœŸç»Ÿè®¡
        stats = by_interval_map.setdefault(interval, {"total": 0, "hit": 0, "score": 0})
        stats["total"] += 1
        stats["score"] += score
        if hit_target:
            stats["hit"] += 1
        
        # æŒ‰ç»“æœç±»å‹ç»Ÿè®¡
        by_outcome_map[outcome_type] = by_outcome_map.get(outcome_type, 0) + 1
    
    by_direction = []
    for direction, stats in by_direction_map.items():
        avg_score = stats["score"] / stats["total"] if stats["total"] > 0 else 0
        by_direction.append((direction, stats["total"], stats["hit"], avg_score))
    
    by_symbol = []
    for symbol, stats in by_symbol_map.items():
        avg_score = stats["score"] / stats["total"] if stats["total"] > 0 else 0
        by_symbol.append((symbol, stats["total"], stats["hit"], avg_score))
    
    by_interval = []
    for interval, stats in by_interval_map.items():
        avg_score = stats["score"] / stats["total"] if stats["total"] > 0 else 0
        by_interval.append((interval, stats["total"], stats["hit"], avg_score))
    
    by_outcome = list(by_outcome_map.items())
    
    avg_score = total_score / total if total > 0 else 0
    
    return {
        "total": total,
        "hit_count": hit_count,
        "avg_score": avg_score,
        "by_direction": by_direction,
        "by_symbol": by_symbol,
        "by_interval": by_interval,
        "by_outcome": by_outcome,
    }

def print_snapshots(limit: int = 10):
    """æ‰“å°å¿«ç…§åˆ—è¡¨"""
    print("\nğŸ“¸ æœ€è¿‘çš„åˆ†æå¿«ç…§")
    print("=" * 90)
    print(f"{'ID':<6} {'äº¤æ˜“å¯¹':<12} {'å‘¨æœŸ':<8} {'æ—¶é—´':<20} {'ä»·æ ¼':<12} {'AIè¾“å‡º'}")
    print("-" * 90)
    
    rows = query_snapshots(limit)
    if not rows:
        print("ï¼ˆæš‚æ— æ•°æ®ï¼‰")
    else:
        for row in rows:
            snapshot_id, symbol, interval, timestamp, price, has_ai = row
            print(f"{snapshot_id:<6} {symbol:<12} {interval:<8} {timestamp:<20} {price:<12.2f} {has_ai}")
    
    print()


def print_outcomes(limit: int = 10):
    """æ‰“å°ç»“æœåˆ—è¡¨ï¼ˆåŸºäº analysis_snapshot.outcome_jsonï¼‰"""
    print("\nğŸ“Š æœ€è¿‘çš„ç»“æœå›å¡«")
    print("=" * 110)
    print(f"{'ID':<6} {'äº¤æ˜“å¯¹':<12} {'å‘¨æœŸ':<8} {'Kçº¿æ•°':<8} {'èµ·å§‹ä»·':<10} {'æœ€é«˜ä»·':<10} {'æœ€ä½ä»·':<10} {'æ–¹å‘':<8} {'å‘½ä¸­ç›®æ ‡':<8}")
    print("-" * 110)
    
    rows = query_outcomes(limit)
    if not rows:
        print("ï¼ˆæš‚æ— æ•°æ®ï¼‰")
    else:
        import json
        for row in rows:
            snapshot_id, symbol, interval, timestamp, price, outcome_json_str = row
            try:
                outcome = json.loads(outcome_json_str)
            except Exception:
                outcome = {}
            direction = outcome.get("direction", "unknown")
            evaluated_bars = outcome.get("evaluated_bars", 0)
            entry_price = outcome.get("entry_price", price)
            max_high = outcome.get("max_high", entry_price)
            min_low = outcome.get("min_low", entry_price)
            hit_target = outcome.get("hit_target", False)
            hit_str = "æ˜¯" if hit_target else "å¦"
            print(f"{snapshot_id:<6} {symbol:<12} {interval:<8} {evaluated_bars:<8} {entry_price:<10.2f} {max_high:<10.2f} {min_low:<10.2f} {direction:<8} {hit_str:<8}")
    
    print()


def print_accuracy():
    """æ‰“å°å‡†ç¡®ç‡ç»Ÿè®¡"""
    stats = calculate_accuracy()
    
    print("\nğŸ“ˆ AI é¢„æµ‹å‡†ç¡®ç‡ç»Ÿè®¡")
    print("=" * 60)
    
    # æ€»ä½“ç»Ÿè®¡
    total = stats["total"]
    hit_count = stats["hit_count"]
    avg_score = stats["avg_score"]
    accuracy = (hit_count / total * 100) if total > 0 else 0
    
    print(f"\næ€»è¯„ä¼°æ¬¡æ•°: {total}")
    print(f"å‘½ä¸­ç›®æ ‡æ¬¡æ•°: {hit_count}")
    print(f"å‘½ä¸­ç‡: {accuracy:.2f}%")
    print(f"å¹³å‡å¾—åˆ†: {avg_score:.2f} / 1.0")
    
    # æŒ‰ç»“æœç±»å‹ç»Ÿè®¡
    if stats["by_outcome"]:
        print("\næŒ‰ç»“æœç±»å‹ç»Ÿè®¡:")
        print("-" * 60)
        for outcome_type, count in sorted(stats["by_outcome"], key=lambda x: x[1], reverse=True):
            percentage = (count / total * 100) if total > 0 else 0
            outcome_name = {
                "success": "âœ“ æˆåŠŸï¼ˆå‘½ä¸­ç›®æ ‡ï¼‰",
                "partial": "â‰ˆ éƒ¨åˆ†æ­£ç¡®ï¼ˆæ–¹å‘å¯¹ä½†æœªè¾¾ç›®æ ‡ï¼‰",
                "stopped": "âŠ— æ­¢æŸå‡ºå±€",
                "failed": "âœ— å¤±è´¥ï¼ˆæ–¹å‘é”™è¯¯ï¼‰",
                "unknown": "? æœªçŸ¥",
                "no_direction": "- æ— æ–¹å‘"
            }.get(outcome_type, outcome_type)
            print(f"  {outcome_name:<30} {count:>3} æ¬¡ ({percentage:>5.1f}%)")
    
    # æŒ‰èµ°åŠ¿æ–¹å‘ç»Ÿè®¡
    if stats["by_direction"]:
        print("\næŒ‰èµ°åŠ¿æ–¹å‘ç»Ÿè®¡:")
        print(f"{'æ–¹å‘':<10} {'è¯„ä¼°æ¬¡æ•°':<12} {'å‘½ä¸­æ¬¡æ•°':<12} {'å¹³å‡å¾—åˆ†':<12} {'å‘½ä¸­ç‡'}")
        print("-" * 70)
        for direction, total_dir, hit_dir, avg_score_dir in stats["by_direction"]:
            acc_dir = (hit_dir / total_dir * 100) if total_dir > 0 else 0
            direction_name = {"up": "çœ‹æ¶¨ â†‘", "down": "çœ‹è·Œ â†“", "unknown": "æœªçŸ¥"}.get(direction, direction)
            print(f"{direction_name:<10} {total_dir:<12} {hit_dir:<12} {avg_score_dir:<12.2f} {acc_dir:.2f}%")
    
    # æŒ‰äº¤æ˜“å¯¹ç»Ÿè®¡
    if stats["by_symbol"]:
        print("\næŒ‰äº¤æ˜“å¯¹ç»Ÿè®¡:")
        print(f"{'äº¤æ˜“å¯¹':<15} {'è¯„ä¼°æ¬¡æ•°':<12} {'å‘½ä¸­æ¬¡æ•°':<12} {'å¹³å‡å¾—åˆ†':<12} {'å‘½ä¸­ç‡'}")
        print("-" * 75)
        for symbol, total_sym, hit_sym, avg_score_sym in stats["by_symbol"]:
            acc_sym = (hit_sym / total_sym * 100) if total_sym > 0 else 0
            print(f"{symbol:<15} {total_sym:<12} {hit_sym:<12} {avg_score_sym:<12.2f} {acc_sym:.2f}%")
    
    # æŒ‰å‘¨æœŸç»Ÿè®¡
    if stats["by_interval"]:
        print("\næŒ‰å‘¨æœŸç»Ÿè®¡:")
        print(f"{'å‘¨æœŸ':<10} {'è¯„ä¼°æ¬¡æ•°':<12} {'å‘½ä¸­æ¬¡æ•°':<12} {'å¹³å‡å¾—åˆ†':<12} {'å‘½ä¸­ç‡'}")
        print("-" * 70)
        for interval, total_int, hit_int, avg_score_int in stats["by_interval"]:
            acc_int = (hit_int / total_int * 100) if total_int > 0 else 0
            print(f"{interval:<10} {total_int:<12} {hit_int:<12} {avg_score_int:<12.2f} {acc_int:.2f}%")
    
    print()


def export_to_csv(filename: str):
    """å¯¼å‡ºè¯„ä¼°ç»“æœåˆ° CSV æ–‡ä»¶
    
    å‚æ•°ï¼š
    - filename: è¾“å‡ºæ–‡ä»¶å
    """
    conn = get_db_conn()
    c = conn.cursor()
    
    c.execute(
        """
        SELECT id, symbol, interval, timestamp, price, ai_json, outcome_json
        FROM analysis_snapshot
        WHERE evaluated = 1 AND outcome_json IS NOT NULL
        ORDER BY timestamp ASC
        """
    )
    
    rows = c.fetchall()
    conn.close()
    
    if not rows:
        print("âš ï¸  æ²¡æœ‰å¯å¯¼å‡ºçš„æ•°æ®")
        return
    
    # å‡†å¤‡ CSV æ•°æ®
    csv_rows = []
    for row in rows:
        snapshot_id, symbol, interval, timestamp, price, ai_json_str, outcome_json_str = row
        
        try:
            ai_data = json.loads(ai_json_str) if ai_json_str else {}
            outcome = json.loads(outcome_json_str)
        except Exception:
            continue
        
        # æå–å…³é”®ä¿¡æ¯
        primary = ai_data.get("primary_scenario", {})
        
        csv_row = {
            "ID": snapshot_id,
            "äº¤æ˜“å¯¹": symbol,
            "å‘¨æœŸ": interval,
            "åˆ†ææ—¶é—´": timestamp,
            "å…¥åœºä»·æ ¼": price,
            "æ–¹å‘": outcome.get("direction", "unknown"),
            "ç›®æ ‡(%)": outcome.get("target_pct", 0),
            "æ­¢æŸ(%)": outcome.get("stop_pct", 0),
            "å‘½ä¸­ç›®æ ‡": "æ˜¯" if outcome.get("hit_target") else "å¦",
            "è§¦å‘æ­¢æŸ": "æ˜¯" if outcome.get("hit_stop") else "å¦",
            "ç»“æœç±»å‹": outcome.get("outcome", "unknown"),
            "å¾—åˆ†": outcome.get("score", 0),
            "æœ€ç»ˆä»·æ ¼": outcome.get("final_price", 0),
            "æœ€ç»ˆå˜åŠ¨(%)": outcome.get("final_move", 0),
            "æœ€å¤§æœ‰åˆ©å˜åŠ¨(%)": outcome.get("max_favorable_move", 0),
            "æœ€å¤§ä¸åˆ©å˜åŠ¨(%)": outcome.get("max_adverse_move", 0),
            "è¯„ä¼°Kçº¿æ•°": outcome.get("evaluated_bars", 0),
            "æœ€é«˜ä»·": outcome.get("max_high", 0),
            "æœ€ä½ä»·": outcome.get("min_low", 0),
            "AIä¿¡å¿ƒåº¦": primary.get("confidence", ""),
            "AIé€»è¾‘": primary.get("logic", "")[:100] if primary.get("logic") else "",  # æˆªå–å‰100å­—ç¬¦
        }
        csv_rows.append(csv_row)
    
    # å†™å…¥ CSV
    if csv_rows:
        fieldnames = csv_rows[0].keys()
        with open(filename, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(csv_rows)
        
        print(f"âœ… å·²å¯¼å‡º {len(csv_rows)} æ¡è®°å½•åˆ°: {filename}")
    else:
        print("âš ï¸  æ²¡æœ‰æœ‰æ•ˆæ•°æ®")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ•°æ®åº“æŸ¥è¯¢ä¸ç»Ÿè®¡å·¥å…·")
    parser.add_argument("--snapshots", action="store_true", help="åªæ˜¾ç¤ºå¿«ç…§åˆ—è¡¨")
    parser.add_argument("--outcomes", action="store_true", help="åªæ˜¾ç¤ºç»“æœåˆ—è¡¨")
    parser.add_argument("--accuracy", action="store_true", help="åªæ˜¾ç¤ºå‡†ç¡®ç‡ç»Ÿè®¡")
    parser.add_argument("--export-csv", type=str, help="å¯¼å‡ºç»“æœåˆ° CSV æ–‡ä»¶")
    parser.add_argument("--limit", type=int, default=10, help="æŸ¥è¯¢è®°å½•æ•°é‡ï¼ˆé»˜è®¤: 10ï¼‰")
    
    args = parser.parse_args()
    
    # CSV å¯¼å‡º
    if args.export_csv:
        export_to_csv(args.export_csv)
        return
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šä»»ä½•é€‰é¡¹ï¼Œæ˜¾ç¤ºæ‰€æœ‰ç»Ÿè®¡
    show_all = not (args.snapshots or args.outcomes or args.accuracy)
    
    if show_all or args.snapshots:
        print_snapshots(args.limit)
    
    if show_all or args.outcomes:
        print_outcomes(args.limit)
    
    if show_all or args.accuracy:
        print_accuracy()
    
    print("âœ… æŸ¥è¯¢å®Œæˆ\n")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­\n")
    except Exception as e:
        print(f"\n\nâŒ é”™è¯¯: {e}\n")
        import traceback
        traceback.print_exc()
